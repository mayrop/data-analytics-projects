---
title: "Artificial Intelligence 5M - Loch Lomond Lake"
author: "Mayra A. Valdes Ibarra - 2419105v"
header-includes: #allows you to add in your own Latex packages
- \usepackage{float} #use the 'float' package
- \floatplacement{figure}{H} #make every figure with caption = h    
output:
  pdf_document:
    latex_engine: pdflatex
    number_sections: yes
    keep_tex: yes
    fig_cap: yes
fontsize: '11pt'
---

```{r, echo = FALSE}
library(knitr)
knitr::opts_chunk$set(echo=FALSE, fig.pos= "h") #knitr::opts_chunk$set(fig.pos = 'H')
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

source("functions.R")
```

```{r libraries, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE}
library(plyr)
library(dplyr)
library(data.table)
library(tidyr)
library(ggplot2)
library(scales)
library(Hmisc)
library(kableExtra)
library(gridExtra)
library(grid)
library(gtable)
library(gridExtra)
library(grid)
library(egg)
library(reshape2)
library(grid)
```

```{r data, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE}
# This environment is derived from the FrozenLake from https://gym.openai.com/envs/#toy_text

# Winter is in Scotland. You and your friends were tossing around a frisbee at Loch Lomond
# when you made a wild throw that left the frisbee out in the middle of the lake.
# The water is mostly frozen, but there are a few holes where the ice has melted.
# If you step into one of those holes, you'll fall into the freezing water.
# At this time, there's an international frisbee shortage, so it's absolutely imperative that
# you navigate across the lake and retrieve the disc.

# However, the ice is slippery, so you won't always move in the direction you intend.
# The surface is described using a grid like the following (for 8x8) with a unknown `problem_id`:

# The specific environment/problem under consideration is a grid-world with a starting position (S), obstacles # (H) and a final goal (G). The task is to get from S to G. The environment is defined in uofgsocsai.py
# via the class LochLomondEnv including documentation relating to the setting, specific states, parameters
# etc. An example of how to instantiate the environment and navigate it using random actions is provided
# in lochlomond_demo.py .
# You must consider three agent types: a senseless/random agent, a simple agent and a reinforcement agent
# based on the requirements listed in the following sections. Your agents will be tested against other instances of the same problem type, i.e., you can not (successfully) hard-code the solution. You will have
# access to eighth specific training instances of the environment determined by the value of a single variable
# problem_id.
# Your agents and findings should be documented in a short (max 1500 word) technical report accompanied
# by the actual implementation/code and evaluation scripts.

```

```{r setup, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE}
palette <- c("#f1c40f", "#48dbfb", "#ff5e57", "#badc58")
names(palette) <- c("S", "F", "H", "G")

grids <- list()
grids[[8]] <- read.csv("../out/grids-8.csv", header=FALSE, stringsAsFactors=FALSE, colClasses = c("character"))
grids[[4]] <- read.csv("../out/grids-4.csv", header=FALSE, stringsAsFactors=FALSE, colClasses = c("character"))
grids[[8]][,"V1"] <- as.numeric(grids[[8]][,"V1"])
grids[[4]][,"V1"] <- as.numeric(grids[[4]][,"V1"])

lakes <- list()
lakes[[4]] <- list()
lakes[[8]] <- list()

for (grid_cols in c(4, 8)) {
  for (problem_id in 1:grid_cols) {
    filename = paste("../out/out_rl_", problem_id - 1, "_", grid_cols, "_policy.csv", sep="")
    policy <- read.csv(filename)
    
    filename <- paste("../out/out_rl_", problem_id - 1, "_", grid_cols, "_u.csv", sep="")
    u <- read.csv(filename)
    
    # take the grid from i (4 or 8) grid and take the problem id "id"
    lake <- grids[[grid_cols]][problem_id,-1]
    lake <- as.factor(lake)
    lakes[[grid_cols]][[problem_id]] <- create_grid(lake, grid_cols)
    lakes[[grid_cols]][[problem_id]] <- lakes[[grid_cols]][[problem_id]] %>% left_join(policy, by=c("x", "y"))
    lakes[[grid_cols]][[problem_id]] <- lakes[[grid_cols]][[problem_id]] %>% left_join(u, by=c("x", "y"))
    lakes[[grid_cols]][[problem_id]]$action_grid <- apply(lakes[[grid_cols]][[problem_id]], 1, arrow_from_cell)
  }
}
```

# Introduction
The Loch Lomond Frozen Lake environment is a customized Open AI Gym derived from FrozenLake (https://gym.openai.com/envs/#toy_text).

The goal of this report is to design, implement and evaluate three diferent virtual agents which are able to navigate across the Loch Lomond Frozen Lake grid and retrieve the frisbee disc. Three different agents are analyzed: a senseless agent, a simple agent and a reinforcement agent. This report includes the analysis for the 8x8 grid, but the analysis of the different variants of the 4x4 grids are included in the Appendices.

# Analysis
```{r, echo = FALSE, eval = FALSE}
# Introduction/motivation and correct PEAS analysis (including task environment characterisation).
# ========
# Your implementation - containing the three different agents (along with any dependencies, except the
# Open AI Gym) - should be uploaded to Moodle as a zip-file containing the source code. You must
# provide three separate and executable python scripts/programs named: run_random.py, run_simple.py
# and run_rl.py which takes as (only required) argument the problem_id . Each script/program should
# include training/learning phases (including possible repetitions/episodes of the problem) and output a
# text file (named after the agent, e.g. ”random”) with any relevant information. Hint: A template will be
# provided via Moodle.
```

```{r environments, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, fig.height = 4, fig.width = 8, out.width = '70%', fig.align = "center"}
# Caption
plot_4 <- finish_plot(ggplot(lakes[[4]][[1]], aes(x_grid, y_grid)))
plot_8 <- finish_plot(ggplot(lakes[[8]][[1]], aes(x_grid, y_grid)))

grid_arrange_shared_legend(
  plot_4 + theme(plot.margin=unit(c(2,2,2,2), "cm")),
  plot_8 + theme(plot.margin=unit(c(0.2,0.2,0.2,0.2), "cm"))
)
```

# Methodology
```{r, echo = FALSE, eval = FALSE}
# The code for all the agents (not in the report!) should be well-documented, follow best-practices in 
# software development and follow the outlined naming convention. The report must contain a presentation of
# relevant aspects of the implementation.
# ========
# Your implementation - containing the three different agents (along with any dependencies, except the
# Open AI Gym) - should be uploaded to Moodle as a zip-file containing the source code. You must
# provide three separate and executable python scripts/programs named: run_random.py, run_simple.py
# and run_rl.py which takes as (only required) argument the problem_id . Each script/program should
# include training/learning phases (including possible repetitions/episodes of the problem) and output a
# text file (named after the agent, e.g. ”random”) with any relevant information. Hint: A template will be
# provided via Moodle.
```

# Implementation
```{r, echo = FALSE, eval = FALSE}
# The code for all the agents (not in the report!) should be well-documented, follow best-practices in 
# software development and follow the outlined naming convention. The report must contain a presentation of
# relevant aspects of the implementation.
# ========
# Your implementation - containing the three different agents (along with any dependencies, except the
# Open AI Gym) - should be uploaded to Moodle as a zip-file containing the source code. You must
# provide three separate and executable python scripts/programs named: run_random.py, run_simple.py
# and run_rl.py which takes as (only required) argument the problem_id . Each script/program should
# include training/learning phases (including possible repetitions/episodes of the problem) and output a
# text file (named after the agent, e.g. "random") with any relevant information. Hint: A template will be
# provided via Moodle.
```

## Senseless Agent

## Simple Agent

## Reinforcement Learning Agent

Additionally, a custom mapper (`EnvMDP` within `helpers.py` file) was implemented to map the enviroment from `Open AI Gym` to a `Grid MDP` in order to produce. It is important to note that the results obtained from the *Policy Iteration* and *Value Iteration* algorithms are completely independent from our reinforcement learning agent, and they are only provided as a measure of comparison of final results from our active reinforcement learning agent.

## Environment Modifications
In order to add additional flexibility and generic support to the agents, slight changes were made to the `uofgsocsai.py` file, the one containing the main `LochLomondEnv` environment class. The changes below were approved as long as justification was provided. The changes and justifications are as follows:

* Parameters `map_name_base`, `reward` and `path_cost` where added to the `LochLomondEnv` constructor. The default values are `8x8-base`, `1.0` and `0` respectively. The default values do not alter the functionality from the original file provided.
* Attributes `is_stochastic`, `reward_hole`, `reward` and `path_cost` were added to the class

The reason of the changes for the constructor was to add flexibility to be able to test different scenarios without the need to modify the file every time a different variant was analyzed. The attributes were added to the class in order to be able to access them via the object (e.g. `env.path_cost`) and create a Markov Decision Process out of it. Even though a Markov Decision Process was out of the scope of this project, an inhouse mapper from `Open AI Gym` environment to `Grid MDP` with the only purpose of doing a sanity check between the final U and policy from the Reinforcement Learning agent and the ones that a *Policy Iteration* and *Value Iteration* algorithm would provide.

Finally, the way to assign en environment grid was changed from `MAPS_BASE[map_name_base]` to `copy.deepcopy(MAPS_BASE)[map_name_base]`, with the only purpose of being able to instantiate the `LochLomondEnv` more than once in a single run (e.g. `python run_rl.py 1,2,3,4,5,6,7`), which runs all the variants in a single run.

There may be other better ways of accomplishing the same without code changes, but due to the current lack of experience/knowledge in Python programming, time did not permit to find better ways for it.

# Evaluation
```{r, echo = FALSE, eval = FALSE}
# An important aspect of RL is assessing and comparing the performance of agents and different policies.
# To document the behavior of your agents you should design a suitable set of (computer) experiments
# which produces a relevant set of graphs/tables to document the behavior of your RL agent (e.g. average
# performance measure vs number of episodes, etc) and compares its performance against the baselines. The
# evaluation strategy should be implemented in a single Python script (a wrapper) run_eval.py which runs
# you entire evaluation, that is, it should call your agents, collate the results and produce the figures/tables
# you have included in your report. The run_eval.py should be submitted via Moodle alongside your
# implementation.
# ========
# - [20%] Evaluation script/program to reproduce the results (i.e. graphs/tables) adhering to the specified
# requirements.
# - [20%] Relevant presentation of the evaluation strategy, metrics and the obtained simulation results. A
# suitable presentation and comparison of the performance of the agent with other agents as evaluated
# across a suitable number of problem variations (e.g. using graphs/tables).
```
Every agent produces different evaluation files that will be created inside the `out` folder.

# Conclusions {#sec:con}

\newpage
# References

\newpage
# Appendices

## Appendix A: Title Here

```{r, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, fig.align = "center", fig.height = 3, fig.width = 10, out.width = '90%', fig.cap = "\\label{fig:appendixa} My caption here"}
grid.arrange(
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[1]], aes(x_grid, y_grid))))) + 
    labs(caption = "Problem 0"),
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[2]], aes(x_grid, y_grid))))) + 
    labs(caption = "Problem 1"),
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[3]], aes(x_grid, y_grid))))) + 
    labs(caption = "Problem 2"),
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[4]], aes(x_grid, y_grid))))) + 
    labs(caption = "Problem 3"),  
  ncol=4
)
```

```{r, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, fig.align = "center", fig.height = 3, fig.width = 10, out.width = '90%', fig.cap = "\\label{fig:appendixa} My caption here"}
grid.arrange(
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[1]], aes(x_grid, y_grid)), key="policy"))) + 
    labs(caption = "Problem 0"),
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[2]], aes(x_grid, y_grid)), key="policy"))) + 
    labs(caption = "Problem 1"),
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[3]], aes(x_grid, y_grid)), key="policy"))) + 
    labs(caption = "Problem 2"),
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[4]][[4]], aes(x_grid, y_grid)), key="policy"))) + 
    labs(caption = "Problem 3"),  
  ncol=4
)
```

```{r, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, fig.align = "center", fig.height = 3, fig.width = 10, out.width = '90%', fig.cap = "\\label{fig:appendixa} My caption here"}
grid.arrange(
  fix_caption(u_plot(lakes[[4]][[1]])) + labs(caption = "Problem 0"),
  fix_caption(u_plot(lakes[[4]][[2]])) + labs(caption = "Problem 1"),
  fix_caption(u_plot(lakes[[4]][[3]])) + labs(caption = "Problem 2"),
  fix_caption(u_plot(lakes[[4]][[4]])) + labs(caption = "Problem 3"),
  ncol=4
)
```

\newpage
## Appendix B: Title Here

```{r lakes3, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, fig.align = "center", fig.height = 4, fig.width = 8, out.width = '85%', fig.cap = "\\label{fig:appendixa} My caption here"}
margin = theme(plot.margin = unit(c(2,2,2,2), "cm"))

grid.arrange(
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[8]][[1]], aes(x_grid, y_grid))))) + 
    labs(caption = "8x8 Grid Problem 0"),
  fix_caption(u_plot(lakes[[8]][[1]])) + labs(caption = "8x8 Problem 0 - Utilities Table"),
  ncol=2
)

grid.arrange(
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[8]][[2]], aes(x_grid, y_grid)), key="policy"))) + 
    labs(caption = "8x8 Grid Problem 1"),
  fix_caption(remove_legend(finish_plot(ggplot(lakes[[8]][[2]], aes(x_grid, y_grid)), key="policy"))) + 
    labs(caption = "8x8 Grid Problem 1"),  
  ncol=2
)
```

[^1]: Russell, Stuart J, and Peter Norvig. *Artificial Intelligence: A Modern Approach*. Englewood Cliffs, N.J: Prentice Hall, 1995. Print.


